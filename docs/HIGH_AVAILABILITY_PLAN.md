# High‑Availability and Scaling Plan

> **Assumption**
> The platform is deployed in a mainstream public‑cloud environment that offers managed or self‑hosted options for distributed data stores, container orchestration and object storage.
> Exact vendor choices (AWS, GCP, Azure, on‑prem Kubernetes, etc.) can be selected to meet cost, skill‑set and regulatory constraints.

| Tier / Service                                            | Deployment & Scale (per active region)                                                                                                    | Replication / Fail‑over                                                                                       | Role & Key Tuning Notes                                                                                                                  |
| --------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
| **Kafka**                    | Three brokers, one per Availability Zone (AZ). Baseline 24 vCPU each; topic partitions sized to peak ingest (e.g. 24 for `supplier.raw`). | Replication factor 3, minimum in‑sync replicas 2. Broker or AZ failure triggers automatic leader re‑election. | Ingestion fan‑out and exactly‑once streaming backbone. Vendor‑agnostic: Confluent Platform, Strimzi on Kubernetes or a managed offering. |
| **Stream‑Processing Coordinator (Flink JobManager HA)**   | Three replicas (one per AZ) managed by the container orchestrator.                                                                        | HA service elects a new leader in < 5 s. Checkpoint to object‑storage every 30 s, savepoint every 5 min.      | Coordinates streaming job; no user traffic.                                                                                              |
| **Stream‑Processing Workers (Flink TaskManagers)**        | Autoscaled: baseline 3 workers per AZ, peaks to 10+. Each worker 4 vCPU / 16 GB.                                                          | Stateless; orchestrator reschedules instantly. Remaining AZs take over partitions; recovery < 30 s.           | Normalises, deduplicates, enriches and validates supplier feeds.                                                                         |
| **In‑Memory Hot Cache (Redis)**                | One primary in AZ‑a plus two replicas in AZ‑b/c (cluster mode).                                                                           | Automatic promotion in \~10 s; client library retries.                                                        | TTL 60 s, LFU eviction, ≈ 2 GB RAM per shard. Implemented via Redis OSS, Redis Enterprise or a managed cache.                            |
| **Full‑Text Search Index (OpenSearch / Elasticsearch)** | Three data nodes (one per AZ). Optional dedicated master set.                                                                             | One replica per shard; index stays green if a node or AZ fails.                                               | Stores structural flight docs (no fare). Refresh interval 1 s. Cloud‑provider managed search or self‑hosted.                             |
| **Durable State Store (NoSQL)**                           | Multi‑AZ, strongly‑consistent key‑value or document store (e.g. DynamoDB, Cosmos DB, Cassandra, FoundationDB).                            | Synchronous replication to three AZs; automatic fail‑over with RPO 0.                                         | Holds latest fare JSON keyed by `flightId`. Provisioned for 10 k RCU start; scales on demand.                                            |
| **API Runtime Pods**                                      | Stateless containers (Kubernetes or serverless). 8 replicas per AZ during peak periods.                                                   | Load‑balancer health‑checks remove failed pods; restart < 5 s.                                                | Combines search‑index IDs with fresh prices and returns JSON/GraphQL.                                                                    |
| **Ingestion Adapters**                                    | Eventing or polling tasks: minimum one per AZ, autoscale to absorb feed bursts.                                                           | If a task dies, Kafka lag grows and autoscaler launches new tasks.                                            | Converts supplier payloads to canonical JSON, writes to `supplier.raw`.                                                                  |
| **Object Storage (Checkpoints & Audit Lake)**             | Regional object store with cross‑region replication.                                                                                      | Durable on full‑AZ loss; replica bucket in DR region.                                                         | Flink checkpoints, raw‑feed retention, and analytics queries.                                                                            |
| **Pilot‑Light DR Region**                                 | Asynchronous log replication, database global tables / replicas, read‑only cache shard, search snapshots, idle JobManager.                | Recovery Point Objective < 5 s, Recovery Time Objective ≈ 15 min (infrastructure‑as‑code).                    | Activated if primary region outage exceeds fail‑over threshold; API and workers start from latest checkpoint.                            |

---

**Why an agnostic approach?**

* Allows the business to negotiate vendor pricing and comply with regional data‑sovereignty rules.
* Keeps the design portable: the same logical architecture can run on managed services, self‑hosted Kubernetes, or a hybrid model.
* Focuses the interview discussion on trade‑offs (latency, cost, operability) rather than vendor‑specific features.
